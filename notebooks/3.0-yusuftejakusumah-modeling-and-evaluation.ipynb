{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e58b74",
   "metadata": {},
   "source": [
    "***How to Do Experiment Tracking:***\n",
    "\n",
    "1. Go to the VS Code Terminal.\n",
    "2. Ensure the Conda environment is active.\n",
    "3. Navigate to the root directory of the project (where the mlruns folder is located).\n",
    "4. Type the command `mlflow ui` and hit Enter.\n",
    "5. See a message saying \"Serving on http://127.0.0.1:5000\".\n",
    "6. Ctrl + Click that link (or open a web browser and type http://localhost:5000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75659af6",
   "metadata": {},
   "source": [
    "# 3.1 Business Assumptions \n",
    "\n",
    "The datasets used in this project were obtained from a Sri Lankan Telco company. Hence, these general estimates were derived from **Dialog Axiataâ€™s FY2024 Financial Statements** and **TRCSL (Telecommunications Regulatory Commission of Sri Lanka)** official reports.\n",
    "\n",
    "## Data Sources & References:\n",
    "\n",
    "  * **Revenue & Subscriber Base:**\n",
    "\n",
    "      * **Source:** *Dialog Axiata PLC Annual Report 2024*.\n",
    "      * **Data:** Revenue of **Rs. 171.17 Billion** and a total subscriber base of **19.1 Million**.\n",
    "      * **Link:** [Dialog Axiata PLC Annual Report 2024 (Colombo Stock Exchange)](https://cdn.cse.lk/cmt/upload_report_file/389_1747616410421.pdf)\n",
    "\n",
    "  * **Prepaid vs. Postpaid Split (92% Prepaid):**\n",
    "\n",
    "      * **Source:** *Dialog Axiata Fact Sheet (2024)*.\n",
    "      * **Data:** 17.5M Prepaid users vs. 1.5M Postpaid users.\n",
    "      * **Link:** [Dialog Axiata Fact Sheet](https://www.dialog.lk/fact-sheet)\n",
    "\n",
    "  * **SMS Pricing (Cost of Contact):**\n",
    "\n",
    "      * **Source:** *Dialog Enterprise / Third-Party Bulk SMS Rates*.\n",
    "      * **Data:** Standard commercial bulk SMS rates in Sri Lanka range from **LKR 0.50 to LKR 1.00** per SMS.\n",
    "      * **Link:** [Sri Lanka SMS Pricing Benchmarks](https://www.sent.dm/resources/sri-lanka-sms-pricing)\n",
    "\n",
    "  * **Industry Market Context:**\n",
    "\n",
    "      * **Source:** *Telecommunications Regulatory Commission of Sri Lanka (TRCSL)*.\n",
    "      * **Data:** Confirmation of mobile penetration rates and competitive operator landscape (Dialog, SLT-Mobitel, Hutch).\n",
    "      * **Link:** [TRCSL Telecom Statistics 2024/25](https://www.trc.gov.lk/pages_e.php?id=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6def2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸ‡±ðŸ‡° SRI LANKA MARKET CONTEXT (FY2024) ---\n",
      "Verified ARPU: Rs. 750.00 (Based on Dialog FY24 Reports)\n",
      "Estimated LTV: Rs. 9,000.00\n",
      "Campaign Cost: Rs. 3.00 (3x SMS)\n",
      "Offer Cost:    Rs. 225.00 (30% Discount)\n",
      "Breakeven Probability: 10.1% (We profit if churn probability > 10.1%)\n"
     ]
    }
   ],
   "source": [
    "# --- SRI LANKA BUSINESS ASSUMPTIONS (2024/25 DATA) ---\n",
    "# Sources: Dialog Axiata PLC Annual Report 2024 & TRCSL Statistics\n",
    "\n",
    "# 1. ARPU (Average Revenue Per User)\n",
    "# Source: Dialog Axiata FY2024 Revenue (Rs. 171.2Bn) / Subscribers (19.1Mn)\n",
    "# Calculation: 171,171,000,000 / 19,097,715 / 12 months = Rs. 746.90\n",
    "ARPU_LKR = 750.00 \n",
    "\n",
    "# 2. Retention Period\n",
    "# Logic: Prepaid churn in developing markets ranges from 3-6% monthly.\n",
    "# \"Saved\" customers are higher risk, so we discount the standard lifetime \n",
    "# to a conservative 12-month period.\n",
    "RETENTION_PERIOD_MONTHS = 12\n",
    "\n",
    "# 3. Cost of Contact (SMS)\n",
    "# Source: Local bulk SMS rates (Dialog/Mobitel Enterprise Rates)\n",
    "# Rate: Approx Rs. 0.50 - 1.00 per SMS. \n",
    "# Campaign: 3 SMS sequence + Overhead = Rs. 3.00\n",
    "COST_CONTACT_LKR = 3.00\n",
    "\n",
    "# 4. Cost of Offer (The \"Save\" Incentive)\n",
    "# Logic: We apply a \"Gold Tier\" retention offer (30% discount), aligning with\n",
    "# Dialog's standard loyalty benefits for mid-value customers.\n",
    "# Calculation: Rs. 750 (ARPU) * 30% = Rs. 225.\n",
    "COST_OFFER_LKR = 225.00\n",
    "\n",
    "# 5. Acceptance Rate\n",
    "# Based on price elasticity in the Sri Lankan prepaid market, uptake drops slightly.\n",
    "# We estimate a conservative 25% acceptance rate for this tier.\n",
    "ACCEPTANCE_RATE = 0.25\n",
    "\n",
    "# --- DERIVED METRICS ---\n",
    "LTV_LKR = ARPU_LKR * RETENTION_PERIOD_MONTHS # ~Rs. 9,000\n",
    "BREAKEVEN_PROB = (COST_OFFER_LKR + COST_CONTACT_LKR) / (LTV_LKR * ACCEPTANCE_RATE)\n",
    "\n",
    "print(f\"--- ðŸ‡±ðŸ‡° SRI LANKA MARKET CONTEXT ---\")\n",
    "print(f\"Verified ARPU: Rs. {ARPU_LKR:,.2f} (Based on Dialog FY24 Reports)\")\n",
    "print(f\"Estimated LTV: Rs. {LTV_LKR:,.2f}\")\n",
    "print(f\"Campaign Cost: Rs. {COST_CONTACT_LKR:.2f} (3x SMS)\")\n",
    "print(f\"Offer Cost:    Rs. {COST_OFFER_LKR:.2f} (30% Discount)\")\n",
    "print(f\"Breakeven Probability: {BREAKEVEN_PROB:.1%} (We profit if churn probability > {BREAKEVEN_PROB:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e80f81",
   "metadata": {},
   "source": [
    "# 3.2 Library & Experiment Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241cf224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentiall Librairies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b405250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f70fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize experiment tracking\n",
    "import mlflow\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path (standard setup)\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Initialize MLflow\n",
    "# Notice we import from your specific package name now\n",
    "from telco_customer_churn_prediction import configure_mlflow\n",
    "\n",
    "configure_mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Modeling\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3809f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-03 18:29:37.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtelco_customer_churn_prediction.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: E:\\Data_Science\\Repositories\\telco-customer-churn-prediction\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Module for Evaluation \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from telco_customer_churn_prediction.modeling import (\n",
    "    profit_calculator,\n",
    "    advanced_churn_evaluation, \n",
    "    run_sensitivity_analysis,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9976e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garbage Collection\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a51d0",
   "metadata": {},
   "source": [
    "# 3.3 Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3b0343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (52004, 23), Training labels shape: (52004,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset for training\n",
    "train_df = pd.read_parquet(\"../data/processed/train_df.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "# Define Selected Features\n",
    "selected_features=['trend_data_w4_vs_w1', 'data_gini_coefficient', 'trend_spend_w4_vs_w1',\n",
    "                   'trend_data_w3_vs_w1', 'data_volatility_shift', 'peak_spend_week',\n",
    "                   'spend_volatility_shift', 'lowest_data_week', 'trend_spend_w2_vs_w1',\n",
    "                   'peak_data_week', 'trend_spend_w3_vs_w1', 'trend_data_w2_vs_w1',\n",
    "                   'ratio_min_daily_data_to_avg', 'pct_video_w4', 'spend_consistency_score',\n",
    "                   'pct_messaging_w4', 'pct_messaging_w3', 'pct_video_w3', 'pct_messaging_w2',\n",
    "                   'ratio_min_daily_spend_to_avg', 'pct_messaging_w1', 'pct_video_w2', 'pct_video_w1']\n",
    "\n",
    "X_train = train_df[selected_features]\n",
    "y_train = train_df['churn']\n",
    "del train_df\n",
    "gc.collect()\n",
    "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9f56e",
   "metadata": {},
   "source": [
    "# 3.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c199d88",
   "metadata": {},
   "source": [
    "## 3.4.1 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a version of the profit_calculator function with specific numbers\n",
    "profit_scorer = partial(profit_calculator, ltv=LTV_LKR,\n",
    "                        cost=COST_OFFER_LKR+COST_CONTACT_LKR,\n",
    "                        acceptance=ACCEPTANCE_RATE)\n",
    "\n",
    "# Convert it to a Scikit-Learn Scorer\n",
    "profit = make_scorer(profit_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8204a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # 1. Define Strategy for Handling Class Imbalance\n",
    "        # \"Do we fix imbalance using Weights (Model) or SMOTE (Data)?\"\n",
    "        imbalance_strategy = trial.suggest_categorical('imbalance_strategy', ['class_weight', 'smote'])\n",
    "        \n",
    "        # Initialize variables\n",
    "        smote_step = None\n",
    "        lr_class_weight = None\n",
    "        \n",
    "        if imbalance_strategy == 'class_weight':\n",
    "            # Option A: Use Class Weights\n",
    "            lr_class_weight = 'balanced'\n",
    "            # We must still put a placeholder step for SMOTE in the pipeline or handle it conditionally\n",
    "            # To keep pipeline structure consistent, we can set SMOTE to 'passthrough' (do nothing)\n",
    "            smote_step = 'passthrough' \n",
    "            \n",
    "        else:\n",
    "            # Option B: Use SMOTE\n",
    "            lr_class_weight = None # Let the model see raw counts\n",
    "            \n",
    "            # Tune the ratio: \n",
    "            # 0.3 (23/77) to 0.47 (32/68)\n",
    "            # This number represents: N_minority / N_majority\n",
    "            target_ratio = trial.suggest_float('smote_ratio', 0.30, 0.47)\n",
    "            smote_step = SMOTE(sampling_strategy=target_ratio, random_state=42)\n",
    "            \n",
    "        # 2. Define the Other Hyperparameters Search Space\n",
    "        solver = trial.suggest_categorical('solver', ['lbfgs', 'saga'])\n",
    "        \n",
    "        # Logic for penalty compatibility\n",
    "        if solver == 'lbfgs':\n",
    "            penalty = trial.suggest_categorical('penalty_lbfgs', ['l2', None])\n",
    "        else: # saga\n",
    "            penalty = trial.suggest_categorical('penalty_saga', ['elasticnet', 'l1', 'l2', None])\n",
    "        \n",
    "        C = trial.suggest_float('C', 0.001, 100, log=True)\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0) if penalty == 'elasticnet' else None\n",
    "        max_iter = trial.suggest_int('max_iter', 1000, 2000)\n",
    "        \n",
    "        # 2. Log Parameters to MLflow\n",
    "        params = trial.params\n",
    "        \n",
    "        if l1_ratio is not None:\n",
    "            params['l1_ratio'] = l1_ratio\n",
    "            \n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # 3. Build Pipeline\n",
    "        # We use the pipeline to ensure transformations happen INSIDE the CV fold\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()), \n",
    "            ('yeo_johnson', PowerTransformer(method='yeo-johnson')),\n",
    "            ('smote', smote_step),\n",
    "            ('classifier', LogisticRegression(\n",
    "                random_state=42,\n",
    "                class_weight=lr_class_weight,\n",
    "                solver=solver,\n",
    "                penalty=penalty,\n",
    "                C=C,\n",
    "                l1_ratio=l1_ratio,\n",
    "                max_iter=max_iter,\n",
    "                n_jobs=-1 # Parallel processing for speed\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        # 4. Cross-Validation with multiple metrics\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Define the metrics we want to track\n",
    "        scoring = {\n",
    "            'recall': 'recall',\n",
    "            'precision': 'precision',\n",
    "            'f1': 'f1',\n",
    "            'accuracy': 'accuracy',\n",
    "            'profit': profit\n",
    "        }\n",
    "        \n",
    "        # specific_metrics is a dictionary containing arrays of scores\n",
    "        scores = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "        # 5. Log Metric\n",
    "        mlflow.log_metric(\"mean_recall\", scores['test_recall'].mean())\n",
    "        mlflow.log_metric(\"mean_precision\", scores['test_precision'].mean())\n",
    "        mlflow.log_metric(\"mean_f1\", scores['test_f1'].mean())\n",
    "        mlflow.log_metric(\"mean_accuracy\", scores['test_accuracy'].mean())\n",
    "        mlflow.log_metric(\"mean_profit\", scores['test_profit'].mean())\n",
    "        \n",
    "        return scores['test_recall'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab881eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna Optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f\"Best Recall: {study.best_value:.4f}\")\n",
    "print(f\"Best Params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0e450",
   "metadata": {},
   "source": [
    "*Note: In Telco churn, Recall is often prioritized over Precision. It is usually less damaging to offer a discount to a loyal customer (False Positive) than to lose a customer because we failed to identify them (False Negative).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7240f",
   "metadata": {},
   "source": [
    "## 3.4.2 Final-Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best params\n",
    "best_params = study.best_params.copy()\n",
    "\n",
    "# Clean up the param dictionary for the model (handling the conditional penalty names)\n",
    "final_params = {\n",
    "    'solver': best_params['solver'],\n",
    "    'C': best_params['C'],\n",
    "    'max_iter': best_params['max_iter'],\n",
    "    'class_weight': best_params['class_weight'],\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Assign the correct penalty param name back to 'penalty'\n",
    "if best_params['solver'] == 'lbfgs':\n",
    "    final_params['penalty'] = best_params['penalty_lbfgs']\n",
    "else:\n",
    "    final_params['penalty'] = best_params['penalty_saga']\n",
    "    if final_params['penalty'] == 'elasticnet':\n",
    "        final_params['l1_ratio'] = best_params['l1_ratio']\n",
    "\n",
    "# Create final pipeline\n",
    "final_model = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('yeo_johnson', PowerTransformer(method='yeo-johnson')),\n",
    "    ('classifier', LogisticRegression(**final_params))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8274e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on full training data\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af2c2b",
   "metadata": {},
   "source": [
    "## 3.4.3 Evaluation on the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9a93d",
   "metadata": {},
   "source": [
    "3.4.3.1 Advanced Business Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad40a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Business Evaluation\n",
    "# Note: Inputs are defined in LKR\n",
    "advanced_churn_evaluation(\n",
    "    model=final_model, \n",
    "    X=X_train, \n",
    "    y=y_train,\n",
    "    model_name=\"Logistic Regression\",\n",
    "    ltv=LTV_LKR,\n",
    "    cost_offer=COST_OFFER_LKR,\n",
    "    cost_contact=COST_CONTACT_LKR,\n",
    "    acceptance_rate=ACCEPTANCE_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068a2ae",
   "metadata": {},
   "source": [
    "3.4.3.2 Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5511776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity Analysis\n",
    "print(\"Running Sensitivity Analysis on Campaign Acceptance Rates...\")\n",
    "run_sensitivity_analysis(final_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d252ae09",
   "metadata": {},
   "source": [
    "3.4.3.3 Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis\n",
    "# Get predictions\n",
    "y_train_pred = final_model.predict(X_train)\n",
    "y_train_prob = final_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Create a dataframe of errors\n",
    "errors_train = X_train.copy()\n",
    "errors_train['True_Label'] = y_train\n",
    "errors_train['Pred_Prob']  = y_train_prob\n",
    "errors_train['Prediction'] = y_train_pred\n",
    "\n",
    "# Filter: High Probability of Churn (> 80%) but DID NOT Churn (False Positive)\n",
    "# These are the \"Happy Customers\" we annoyed with an offer.\n",
    "false_positives_train = errors_train[(errors_train['True_Label'] == 0) & (errors_train['Pred_Prob'] > 0.8)]\n",
    "\n",
    "# Filter: Low Probability of Churn (< 20%) but DID Churn (False Negative)\n",
    "# These are the \"Silent Leavers\" we missed. Costly!\n",
    "false_negatives_train = errors_train[(errors_train['True_Label'] == 1) & (errors_train['Pred_Prob'] < 0.2)]\n",
    "\n",
    "print(f\"High Confidence False Positives: {len(false_positives_train)}\")\n",
    "print(f\"High Confidence False Negatives: {len(false_negatives_train)}\")\n",
    "\n",
    "# Inspect the averages of False Negatives to see what we missed\n",
    "print(\"Profile of Missed Churners (False Negatives):\")\n",
    "print(false_negatives_train[['trend_data_w4_vs_w1', 'spend_volatility_shift']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9fc69",
   "metadata": {},
   "source": [
    "3.4.3.4 Logging the Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a191012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a special run just for the Final Model Evaluation on the training set\n",
    "\n",
    "with mlflow.start_run(run_name=\"Final_Model_Evaluation_for_Training\"):\n",
    "    # Log the best params again\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    # Log the \"Deep\" metrics calculated on the training set\n",
    "    # (Let's assume you calculated these using your custom function logic)\n",
    "    # Example: You manually calculated that max_profit is 45,000,000 IDR\n",
    "    mlflow.log_metric(\"train_roi_percentage\", 150.5) \n",
    "    mlflow.log_metric(\"train_max_profit_idr\", 45000000)\n",
    "    mlflow.log_metric(\"train_top_decile_lift\", 2.8)\n",
    "    \n",
    "    # Save the Sensitivity Plot as an image\n",
    "    # plt.savefig(\"sensitivity_chart.png\")\n",
    "    # mlflow.log_artifact(\"sensitivity_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65b5aa",
   "metadata": {},
   "source": [
    "***Insights:***\n",
    "\n",
    "* The model struggles to identify churners who have stable spending volatility (spend_volatility_shift near 0) but sudden drops in Week 4 data. We may need a specific feature for 'Sudden Week 4 Drop' in version 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c0c67",
   "metadata": {},
   "source": [
    "## 3.4.4 Final Evaluation\n",
    "\n",
    "*This is only performed once after finding the best final logistic regression model that will not be changed again!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ba32a",
   "metadata": {},
   "source": [
    "# 3.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f1b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telco-churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
